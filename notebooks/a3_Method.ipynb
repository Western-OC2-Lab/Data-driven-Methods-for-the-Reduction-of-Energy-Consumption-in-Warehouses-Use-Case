{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(\"../datasets/generated/2019_z2_Floor6.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd410220",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_frames = np.unique(sample_df.frame_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee57bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df.drop(columns = ['frame_id'], inplace=True)\n",
    "sample_df['output'] = sample_df['z2_AC1(kW)']\n",
    "# sample_df.drop(columns = ['z2_AC1(kW)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db71aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_based_FE(df, lag_length, future, step):\n",
    "    new_df = df.copy()\n",
    "    for feature in new_df.columns:\n",
    "        if feature != \"output\":\n",
    "            for i in range(1, lag_length, step):\n",
    "                new_df.loc[:, f'{feature}_{i}'] = new_df.loc[:, feature].shift(periods = i)\n",
    "            new_df.drop(columns = [feature], inplace=True)\n",
    "        \n",
    "    new_df.loc[:, 'output'] = new_df.loc[:, 'output'].shift(periods = -future)\n",
    "    new_df.dropna(inplace=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_df_frames(all_df, lag_length, future, step, frames):\n",
    "    df = pd.DataFrame()\n",
    "    for frame in tqdm(frames):\n",
    "        df_frame = all_df.loc[all_df.frame_id == frame, :]\n",
    "        df_frame.drop(columns = ['frame_id'], inplace=True)\n",
    "        lagged_frame = lag_based_FE(df_frame, lag_length, future, step)\n",
    "        df = pd.concat([df, lagged_frame])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d453c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm.notebook import trange, tqdm\n",
    "algorith_parm_map = {\n",
    "    'rf': {'max_depth': [3, 5, 10],\n",
    "               'min_samples_split': [2, 5, 10]},\n",
    "    'gboost': {'max_depth': [3, 5, 10],\n",
    "               'min_samples_split': [2, 5, 10]},\n",
    "    'lasso': {'alpha': np.logspace(-4, -0.5, 10)},\n",
    "    'ridge': {'alpha': np.logspace(-4, -0.5, 10)}\n",
    "}\n",
    "\n",
    "set_hs_fs = [[5, 5], [10, 10],[15, 15],[20, 20]]\n",
    "alg_best = pd.DataFrame()\n",
    "random_frames = np.random.choice(unique_frames.shape[0], 120)\n",
    "test_size = 0.7\n",
    "training_frames, testing_frames = unique_frames[random_frames[:int(test_size*len(random_frames))]], unique_frames[random_frames[int(test_size*len(random_frames)):]]\n",
    "\n",
    "for h_f in tqdm(set_hs_fs):\n",
    "    dict_result = {}\n",
    "    h, f = h_f[0], h_f[1]\n",
    "    dict_result['history'], dict_result['future'] = h, f\n",
    "    training_set, validation_set = produce_df_frames(sample_df, h, f, 1, training_frames), produce_df_frames(sample_df, h, f, 1, testing_frames)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_df = pd.DataFrame(np.c_[training_set.output.values, scaler.fit_transform(training_set.drop(columns = ['output']))], columns = training_set.columns)\n",
    "    scaled_validation_df = pd.DataFrame(np.c_[validation_set.output.values, scaler.transform(validation_set.drop(columns = ['output']))], columns = training_set.columns)\n",
    "    \n",
    "    for alg in tqdm(algorith_parm_map.keys()):\n",
    "\n",
    "        param_grid = algorith_parm_map[alg]\n",
    "        base_estimator = None\n",
    "        if alg == 'rf':\n",
    "            base_estimator = RandomForestRegressor(random_state = 0)\n",
    "        elif alg == 'gboost':\n",
    "            base_estimator = GradientBoostingRegressor(random_state = 0)\n",
    "        elif alg == 'lasso':\n",
    "            base_estimator = Lasso(random_state = 0)\n",
    "        else:\n",
    "            base_estimator = Ridge(random_state = 0)\n",
    "\n",
    "        cv_regressor = GridSearchCV(base_estimator, param_grid, scoring = 'neg_mean_absolute_error', cv = 3, verbose=1)\n",
    "        X_train, y_train = scaled_train_df.drop(columns  =['output']), scaled_train_df.output.values\n",
    "        X_validation, y_validation = scaled_validation_df.drop(columns  =['output']), scaled_validation_df.output.values\n",
    "\n",
    "        cv_regressor.fit(X_train, y_train)\n",
    "        results_df = pd.DataFrame.from_dict(cv_regressor.cv_results_)\n",
    "        y_predictions = cv_regressor.predict(X_validation)\n",
    "        dict_result[alg] = mean_absolute_error(y_validation, y_predictions)\n",
    "\n",
    "        results_df.to_csv(f\"../results/stats/2019_z2_Floor6_m3_{alg}_h-{h}_f-{f}_training.csv\")\n",
    "    alg_best = pd.concat([alg_best, pd.DataFrame.from_dict([dict_result])])\n",
    "alg_best.to_csv(\"../results/stats/2019_z2_Floor6_m3_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7157c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194fb121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
