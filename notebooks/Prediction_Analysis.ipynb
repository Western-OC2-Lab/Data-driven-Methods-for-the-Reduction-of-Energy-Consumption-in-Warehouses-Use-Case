{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb73d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f0c73",
   "metadata": {},
   "source": [
    "# Method 3 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965102c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"../datasets/generated/2019_z2_Floor6.csv\", index_col=[0])\n",
    "z1_data = pd.read_csv(\"../datasets/generated/2019_z1_Floor6.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48df818",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.index = pd.to_datetime(training_data.index)\n",
    "z1_data.index = pd.to_datetime(z1_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83038a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['output'] = training_data['z2_AC1(kW)']\n",
    "z1_data['output'] = z1_data['z1_AC1(kW)']\n",
    "\n",
    "unique_frames = np.unique(training_data.frame_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47223c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_frames_z1 = np.unique(z1_data.frame_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d70e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_df_frames(all_df, lag_length, future, step, frames):\n",
    "    df = pd.DataFrame()\n",
    "    for frame in tqdm(frames):\n",
    "        df_frame = all_df.loc[all_df.frame_id == frame, :]\n",
    "        df_frame.drop(columns = ['frame_id'], inplace=True)\n",
    "        lagged_frame = lag_based_FE(df_frame, lag_length, future, step)\n",
    "        df = pd.concat([df, lagged_frame])\n",
    "    return df\n",
    "def lag_based_FE(df, lag_length, future, step):\n",
    "    new_df = df.copy()\n",
    "    for feature in new_df.columns:\n",
    "        if feature != \"output\":\n",
    "            for i in range(1, lag_length, step):\n",
    "                new_df.loc[:, f'{feature}_{i}'] = new_df.loc[:, feature].shift(periods = i)\n",
    "            new_df.drop(columns = [feature], inplace=True)\n",
    "        \n",
    "    new_df.loc[:, 'output'] = new_df.loc[:, 'output'].shift(periods = -future)\n",
    "    new_df.dropna(inplace=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac38982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPO_algorithms = {\n",
    "    5: GradientBoostingRegressor(max_depth = 3, min_samples_split = 10),\n",
    "    10: GradientBoostingRegressor(max_depth = 10, min_samples_split = 10),\n",
    "    15: GradientBoostingRegressor(max_depth = 10, min_samples_split = 10),\n",
    "    20: GradientBoostingRegressor(max_depth = 10, min_samples_split = 5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712cab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "_, bins = np.histogram(training_data.output.values, bins = 5)\n",
    "\n",
    "# set_hs_fs = [[5, 5], [10, 10],[15, 15],[20, 20]]\n",
    "# set_hs_fs = [[5, 5],[20, 20]]\n",
    "set_hs_fs = [[10, 10]]\n",
    "\n",
    "\n",
    "alg_best_months = pd.DataFrame()\n",
    "\n",
    "\n",
    "for h_f in tqdm(set_hs_fs):\n",
    "    dict_result = {}\n",
    "    h, f = h_f[0], h_f[1]\n",
    "    \n",
    "    for month in [3, 10]:\n",
    "        month_data = training_data.loc[training_data.index.month == month, :]\n",
    "        nonmonth_data = training_data.loc[training_data.index.month != month, :]\n",
    "        \n",
    "        month_data_z1 = z1_data.loc[z1_data.index.month == month, :]\n",
    "#         intersection_indices = np.intersect1d(month_data.index, month_data_z1.index, return_indices=True)\n",
    "        \n",
    "#         month_data_z1 = month_data_z1.loc[intersection_indices[0], :]\n",
    "#         month_data = month_data.loc[intersection_indices[0], :]\n",
    "#         print(month_data.shape, month_data_z1.shape)\n",
    "        \n",
    "        training_frames, validation_frames = np.unique(nonmonth_data.frame_id.values), np.unique(month_data.frame_id.values)\n",
    "        z1_frames = np.unique(month_data_z1.frame_id.values)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        training_set, validation_set = produce_df_frames(nonmonth_data, h, f, 1, training_frames), produce_df_frames(month_data, h, f, 1, validation_frames)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        z1_frame_data  = produce_df_frames(month_data_z1, h, f, 1, z1_frames)\n",
    "        \n",
    "        intersection_indices = np.intersect1d(validation_set.index, z1_frame_data.index, return_indices=True)\n",
    "        \n",
    "        month_data_z1 = month_data_z1.loc[intersection_indices[0], :]\n",
    "        validation_set = validation_set.loc[intersection_indices[0], :]\n",
    "\n",
    "        \n",
    "        total_seq_time = round((end_time - start_time) /60, 2)\n",
    "#         dict_result['preprocess_time'] = total_seq_time\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaled_train_df = pd.DataFrame(np.c_[training_set.output.values, scaler.fit_transform(training_set.drop(columns = ['output']))], columns = training_set.columns)\n",
    "        scaled_validation_df = pd.DataFrame(np.c_[validation_set.output.values, scaler.transform(validation_set.drop(columns = ['output']))], columns = training_set.columns)\n",
    "        \n",
    "        \n",
    "        base_estimator = HPO_algorithms[h]\n",
    "        X_train, y_train = scaled_train_df.drop(columns  =['output']), scaled_train_df.output.values\n",
    "        X_validation, y_validation = scaled_validation_df.drop(columns  =['output']), scaled_validation_df.output.values\n",
    "        \n",
    "        start_time = time.time()\n",
    "        base_estimator.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        total_train_time = round((end_time - start_time) /60, 2)\n",
    "        dict_result['total_train_time'] = total_train_time\n",
    "        predictions = base_estimator.predict(X_validation)\n",
    "        \n",
    "        for col in month_data_z1.columns[:-2]:\n",
    "            dict_result['month'] = month\n",
    "            dict_result['history'], dict_result['future'] = h, f\n",
    "            dict_result['parameter'] = col\n",
    "            \n",
    "            col_values = month_data_z1[[col]].values.reshape(-1,)\n",
    "            loss = (y_validation - predictions)\n",
    "            ae = abs(y_validation - predictions)\n",
    "            corr_1, _ = pearsonr(col_values,y_validation)\n",
    "            corr_loss, _ = pearsonr(col_values,loss)\n",
    "            corr_ae, _ = pearsonr(col_values,ae)\n",
    "            \n",
    "            dict_result['corr_orig'] = corr_1\n",
    "            dict_result['corr_loss'] = corr_loss\n",
    "            dict_result['corr_ae'] = corr_ae\n",
    "            \n",
    "            dict_result['r2_score'] = r2_score(y_validation, predictions)\n",
    "            \n",
    "            alg_best_months = pd.concat([alg_best_months, pd.DataFrame.from_dict([dict_result])])\n",
    "    alg_best_months.index = range(alg_best_months.shape[0])\n",
    "alg_best_months.to_csv(\"../results/stats/stats_2019_z2_Floor6_m3_correlation_z1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_best_months.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047197cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
